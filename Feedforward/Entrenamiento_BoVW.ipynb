{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de red Feedforward \n",
    "\n",
    "Con el dataset creado anteriormente con 1000 características y una columna para clase, vamos a entrenar la red FF con múltiples corridas guardando cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 45 kB/s  eta 0:00:01    |█████▍                          | 54.2 MB 7.9 MB/s eta 0:00:34\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.11.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.9.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.18.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.27.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow-gpu) (46.0.0.post20200310)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.3.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard, astunparse, gast, tensorflow-estimator, opt-einsum, keras-preprocessing, tensorflow-gpu\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.0\n",
      "    Uninstalling tensorboard-2.1.0:\n",
      "      Successfully uninstalled tensorboard-2.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 0+untagged.53.g6ab433b.dirty\n",
      "    Uninstalling opt-einsum-0+untagged.53.g6ab433b.dirty:\n",
      "      Successfully uninstalled opt-einsum-0+untagged.53.g6ab433b.dirty\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 keras-preprocessing-1.1.2 opt-einsum-3.3.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.1\n"
     ]
    }
   ],
   "source": [
    "#Llamamos las librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamamos el dataset a un dataframe de pandas\n",
    "dataset = pd.read_csv(\"DataSet_NoVehiculo_Vehiculo.csv\")\n",
    "#Ahora lo dividimos en salida y entrada, la salida es la última columna\n",
    "#0 indica NO VEHICULO\n",
    "#1 indica VEHICULO\n",
    "Y = dataset[dataset.columns[-1]]\n",
    "X = dataset[dataset.columns[:-1]]\n",
    "#Separamos en Test y Train con ayuda de sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 1s 98us/sample - loss: 0.6028 - acc: 0.7037 - val_loss: 0.5378 - val_acc: 0.7912\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.4529 - acc: 0.8262 - val_loss: 0.4303 - val_acc: 0.8230\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.3547 - acc: 0.8582 - val_loss: 0.3705 - val_acc: 0.8312\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2938 - acc: 0.8822 - val_loss: 0.3402 - val_acc: 0.8517\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.2520 - acc: 0.9023 - val_loss: 0.3196 - val_acc: 0.8649\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.2203 - acc: 0.9173 - val_loss: 0.3027 - val_acc: 0.8690\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1954 - acc: 0.9292 - val_loss: 0.2940 - val_acc: 0.8744\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.1751 - acc: 0.9384 - val_loss: 0.2873 - val_acc: 0.8790\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1582 - acc: 0.9460 - val_loss: 0.2843 - val_acc: 0.8872\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1436 - acc: 0.9524 - val_loss: 0.2817 - val_acc: 0.8881\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 1s 123us/sample - loss: 0.5913 - acc: 0.7265 - val_loss: 0.5185 - val_acc: 0.7875\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.4352 - acc: 0.8332 - val_loss: 0.4158 - val_acc: 0.8235\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.3416 - acc: 0.8671 - val_loss: 0.3618 - val_acc: 0.8453\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.2852 - acc: 0.8880 - val_loss: 0.3304 - val_acc: 0.8612\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.2472 - acc: 0.9058 - val_loss: 0.3096 - val_acc: 0.8699\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.2182 - acc: 0.9206 - val_loss: 0.2976 - val_acc: 0.8776\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1950 - acc: 0.9321 - val_loss: 0.2863 - val_acc: 0.8840\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1760 - acc: 0.9403 - val_loss: 0.2818 - val_acc: 0.8858\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1598 - acc: 0.9471 - val_loss: 0.2781 - val_acc: 0.8894\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1462 - acc: 0.9551 - val_loss: 0.2743 - val_acc: 0.8931\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 97us/sample - loss: 0.5796 - acc: 0.7415 - val_loss: 0.5226 - val_acc: 0.7775\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.4369 - acc: 0.8291 - val_loss: 0.4291 - val_acc: 0.8126\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.3473 - acc: 0.8660 - val_loss: 0.3776 - val_acc: 0.8289\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.2908 - acc: 0.8876 - val_loss: 0.3466 - val_acc: 0.8453\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2512 - acc: 0.9064 - val_loss: 0.3264 - val_acc: 0.8576\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2207 - acc: 0.9175 - val_loss: 0.3098 - val_acc: 0.8608\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.1963 - acc: 0.9300 - val_loss: 0.3002 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.1758 - acc: 0.9374 - val_loss: 0.2943 - val_acc: 0.8690\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1587 - acc: 0.9465 - val_loss: 0.2902 - val_acc: 0.8717\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1440 - acc: 0.9516 - val_loss: 0.2878 - val_acc: 0.8763\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 1s 98us/sample - loss: 0.6034 - acc: 0.7107 - val_loss: 0.5418 - val_acc: 0.7871\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.4543 - acc: 0.8244 - val_loss: 0.4382 - val_acc: 0.8162\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.3558 - acc: 0.8568 - val_loss: 0.3811 - val_acc: 0.8348\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.2956 - acc: 0.8802 - val_loss: 0.3495 - val_acc: 0.8535\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2539 - acc: 0.9009 - val_loss: 0.3276 - val_acc: 0.8649\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2220 - acc: 0.9177 - val_loss: 0.3111 - val_acc: 0.8712\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1971 - acc: 0.9270 - val_loss: 0.3010 - val_acc: 0.8799\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1768 - acc: 0.9364 - val_loss: 0.2917 - val_acc: 0.8822\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1595 - acc: 0.9456 - val_loss: 0.2900 - val_acc: 0.8817\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1451 - acc: 0.9534 - val_loss: 0.2852 - val_acc: 0.8863\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 96us/sample - loss: 0.5962 - acc: 0.7074 - val_loss: 0.5258 - val_acc: 0.7944\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.4422 - acc: 0.8262 - val_loss: 0.4240 - val_acc: 0.8189\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.3485 - acc: 0.8591 - val_loss: 0.3709 - val_acc: 0.8339\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.2902 - acc: 0.8855 - val_loss: 0.3380 - val_acc: 0.8512\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2492 - acc: 0.9036 - val_loss: 0.3149 - val_acc: 0.8571\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2182 - acc: 0.9194 - val_loss: 0.3027 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1939 - acc: 0.9313 - val_loss: 0.2952 - val_acc: 0.8735\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 59us/sample - loss: 0.1739 - acc: 0.9395 - val_loss: 0.2877 - val_acc: 0.8794\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1571 - acc: 0.9446 - val_loss: 0.2828 - val_acc: 0.8844\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1428 - acc: 0.9512 - val_loss: 0.2821 - val_acc: 0.8867\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 97us/sample - loss: 0.5997 - acc: 0.6988 - val_loss: 0.5270 - val_acc: 0.7948\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.4437 - acc: 0.8400 - val_loss: 0.4214 - val_acc: 0.8198\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.3466 - acc: 0.8707 - val_loss: 0.3628 - val_acc: 0.8403\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 60us/sample - loss: 0.2887 - acc: 0.8884 - val_loss: 0.3324 - val_acc: 0.8499\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 61us/sample - loss: 0.2489 - acc: 0.9038 - val_loss: 0.3142 - val_acc: 0.8644\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2184 - acc: 0.9157 - val_loss: 0.2960 - val_acc: 0.8722\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1938 - acc: 0.9284 - val_loss: 0.2871 - val_acc: 0.8781\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.1737 - acc: 0.9372 - val_loss: 0.2795 - val_acc: 0.8799\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1570 - acc: 0.9438 - val_loss: 0.2766 - val_acc: 0.8840\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.1427 - acc: 0.9526 - val_loss: 0.2759 - val_acc: 0.8876\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 97us/sample - loss: 0.5975 - acc: 0.7142 - val_loss: 0.5335 - val_acc: 0.7798\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.4463 - acc: 0.8307 - val_loss: 0.4310 - val_acc: 0.8107\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.3496 - acc: 0.8570 - val_loss: 0.3774 - val_acc: 0.8348\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2895 - acc: 0.8831 - val_loss: 0.3433 - val_acc: 0.8508\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2481 - acc: 0.8995 - val_loss: 0.3246 - val_acc: 0.8658\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2170 - acc: 0.9132 - val_loss: 0.3090 - val_acc: 0.8699\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1925 - acc: 0.9243 - val_loss: 0.3019 - val_acc: 0.8758\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1732 - acc: 0.9317 - val_loss: 0.2937 - val_acc: 0.8763\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1569 - acc: 0.9409 - val_loss: 0.2902 - val_acc: 0.8817\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1431 - acc: 0.9503 - val_loss: 0.2880 - val_acc: 0.8831\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 97us/sample - loss: 0.5892 - acc: 0.7337 - val_loss: 0.5249 - val_acc: 0.7775\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.4420 - acc: 0.8293 - val_loss: 0.4250 - val_acc: 0.8107\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.3482 - acc: 0.8642 - val_loss: 0.3724 - val_acc: 0.8371\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2910 - acc: 0.8867 - val_loss: 0.3396 - val_acc: 0.8494\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2506 - acc: 0.9021 - val_loss: 0.3179 - val_acc: 0.8599\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2195 - acc: 0.9175 - val_loss: 0.3013 - val_acc: 0.8672\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1957 - acc: 0.9278 - val_loss: 0.2942 - val_acc: 0.8722\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1761 - acc: 0.9364 - val_loss: 0.2864 - val_acc: 0.8758\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.1595 - acc: 0.9446 - val_loss: 0.2847 - val_acc: 0.8790\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1456 - acc: 0.9510 - val_loss: 0.2816 - val_acc: 0.8826\n",
      "Train on 5126 samples, validate on 2198 samples\n",
      "Epoch 1/10\n",
      "5126/5126 [==============================] - 0s 96us/sample - loss: 0.5759 - acc: 0.7450 - val_loss: 0.5111 - val_acc: 0.8016\n",
      "Epoch 2/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.4250 - acc: 0.8361 - val_loss: 0.4129 - val_acc: 0.8280\n",
      "Epoch 3/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.3341 - acc: 0.8685 - val_loss: 0.3700 - val_acc: 0.8453\n",
      "Epoch 4/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2787 - acc: 0.8909 - val_loss: 0.3398 - val_acc: 0.8558\n",
      "Epoch 5/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.2406 - acc: 0.9087 - val_loss: 0.3207 - val_acc: 0.8621\n",
      "Epoch 6/10\n",
      "5126/5126 [==============================] - 0s 57us/sample - loss: 0.2118 - acc: 0.9233 - val_loss: 0.3077 - val_acc: 0.8708\n",
      "Epoch 7/10\n",
      "5126/5126 [==============================] - 0s 56us/sample - loss: 0.1889 - acc: 0.9331 - val_loss: 0.2994 - val_acc: 0.8703\n",
      "Epoch 8/10\n",
      "5126/5126 [==============================] - 0s 55us/sample - loss: 0.1703 - acc: 0.9423 - val_loss: 0.2958 - val_acc: 0.8772\n",
      "Epoch 9/10\n",
      "5126/5126 [==============================] - 0s 58us/sample - loss: 0.1548 - acc: 0.9501 - val_loss: 0.2933 - val_acc: 0.8781\n",
      "Epoch 10/10\n",
      "5126/5126 [==============================] - 0s 60us/sample - loss: 0.1415 - acc: 0.9569 - val_loss: 0.2915 - val_acc: 0.8794\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 100,201\n",
      "Trainable params: 100,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for i in range(1,10):\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(100,input_shape=(1000,),activation='relu',kernel_initializer='random_normal',bias_initializer='zeros'))\n",
    "    modelo.add(Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer='zeros'))\n",
    "\n",
    "    modelo.compile(optimizer=tensorflow.keras.optimizers.SGD(lr=0.01), loss='binary_crossentropy',metrics=['acc'])\n",
    "    history.append(modelo.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=10,batch_size=32))\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
