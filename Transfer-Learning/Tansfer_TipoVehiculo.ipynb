{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyunpack\n",
      "  Downloading pyunpack-0.2.2-py2.py3-none-any.whl (3.8 kB)\n",
      "Collecting entrypoint2\n",
      "  Downloading entrypoint2-0.2.3-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting easyprocess\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse, entrypoint2, easyprocess, pyunpack\n",
      "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.3 pyunpack-0.2.2\n",
      "Collecting patool\n",
      "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: patool\n",
      "Successfully installed patool-1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install pyunpack\n",
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías necesarias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from pyunpack import Archive\n",
    "#from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descompresión de las imágenes\n",
    "os.mkdir('dataset')\n",
    "Archive('TipoVehiculo.rar').extractall('dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8600 images belonging to 8 classes.\n",
      "Found 1576 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#Se cargan los conjustos de imágenes y se reescalan\n",
    "\n",
    "#train_dir = os.path.join('dataset/TipoVehiculo/Train')\n",
    "#validation_dir = os.path.join('dataset/TipoVehiculo/Validation')\n",
    "#test_dir = os.path.join('dataset/TipoVehiculo/test')\n",
    "\n",
    "BATCH_SIZE = 15\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    validation_split = 0.3)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='dataset/TipoVehiculo/Train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=15,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory='dataset/TipoVehiculo/Validation', # same directory as training data\n",
    "    target_size=(224, 224),\n",
    "    batch_size=15,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar la escala de los valores de píxeles de las imágenes \n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "#rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación sel modelo base a partir del modelo previamente entrenado MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "#Congelar la base convolucional\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar un encabezado de clasificación\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(8,activation='softmax',kernel_initializer='random_normal',bias_initializer='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar aumento de datos\n",
    "\n",
    "data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=30, horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(dataz, filename): \n",
    "    with open(filename,'w') as f: \n",
    "        json.dump(dataz, f, indent=4) \n",
    "\n",
    "data = []\n",
    "\n",
    "with open('history.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 574 steps, validate for 106 steps\n",
      "Epoch 1/100\n",
      "574/574 [==============================] - 167s 290ms/step - loss: 1.8883 - accuracy: 0.3864 - val_loss: 1.8905 - val_accuracy: 0.3871\n",
      "Epoch 2/100\n",
      "574/574 [==============================] - 168s 293ms/step - loss: 1.8881 - accuracy: 0.3864 - val_loss: 1.8905 - val_accuracy: 0.3871\n",
      "Epoch 3/100\n",
      "574/574 [==============================] - 168s 292ms/step - loss: 1.8880 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 4/100\n",
      "574/574 [==============================] - 176s 306ms/step - loss: 1.8880 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 5/100\n",
      "574/574 [==============================] - 173s 301ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 6/100\n",
      "574/574 [==============================] - 174s 303ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 7/100\n",
      "574/574 [==============================] - 174s 303ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 8/100\n",
      "574/574 [==============================] - 174s 302ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 9/100\n",
      "574/574 [==============================] - 172s 300ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 10/100\n",
      "574/574 [==============================] - 172s 300ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 11/100\n",
      "574/574 [==============================] - 175s 306ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 12/100\n",
      "574/574 [==============================] - 175s 305ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 13/100\n",
      "574/574 [==============================] - 171s 299ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 14/100\n",
      "574/574 [==============================] - 179s 311ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 15/100\n",
      "574/574 [==============================] - 174s 303ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 16/100\n",
      "574/574 [==============================] - 174s 303ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 17/100\n",
      "574/574 [==============================] - 176s 307ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 18/100\n",
      "574/574 [==============================] - 176s 307ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 19/100\n",
      "574/574 [==============================] - 173s 302ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 20/100\n",
      "574/574 [==============================] - 174s 303ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 21/100\n",
      "574/574 [==============================] - 178s 311ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 22/100\n",
      "574/574 [==============================] - 175s 305ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 23/100\n",
      "574/574 [==============================] - 177s 308ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 24/100\n",
      "574/574 [==============================] - 172s 300ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 25/100\n",
      "574/574 [==============================] - 178s 310ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 26/100\n",
      "574/574 [==============================] - 173s 302ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 27/100\n",
      "574/574 [==============================] - 177s 309ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 28/100\n",
      "574/574 [==============================] - 178s 310ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 29/100\n",
      "574/574 [==============================] - 178s 309ms/step - loss: 1.8879 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 30/100\n",
      "574/574 [==============================] - 175s 306ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 31/100\n",
      "574/574 [==============================] - 178s 310ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 32/100\n",
      "574/574 [==============================] - 176s 307ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 33/100\n",
      "574/574 [==============================] - 177s 308ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 34/100\n",
      "574/574 [==============================] - 175s 304ms/step - loss: 1.8878 - accuracy: 0.3864 - val_loss: 1.8904 - val_accuracy: 0.3871\n",
      "Epoch 35/100\n",
      "484/574 [========================>.....] - ETA: 23s - loss: 1.8841 - accuracy: 0.3899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-44f4e2b6f2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Compilar el modelo y entrenarlo\n",
    "\n",
    "#os.mkdir('modelos')\n",
    "base_learning_rate = 0.005\n",
    "history = []\n",
    "contador = 0\n",
    "\n",
    "for i in range(1,101):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    #x = data_augmentation(inputs)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    mcp_save = ModelCheckpoint('modelos/transfer_learning_'+str(i)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min',save_weights_only=False)\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    history.append(model.fit(train_generator,epochs=100,callbacks=[mcp_save],validation_data=validation_generator)) \n",
    "\n",
    "    with open('history.json') as json_file: \n",
    "        datay = json.load(json_file) \n",
    "     \n",
    "        temp = datay\n",
    "\n",
    "        y = { 'accuracy': history[contador].history['accuracy'],\n",
    "            'loss': history[contador].history['val_loss']\n",
    "            }            \n",
    "\n",
    "        temp.append(y) \n",
    "    write_json(datay, 'history.json')  \n",
    " \n",
    "    contador = contador + 1\n",
    "\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualización de los resultados en gráficas\n",
    "\n",
    "for i in range(len(history)):\n",
    "  plt.plot(history[i].history['accuracy'])\n",
    "plt.title('Exactitud del modelo')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.xlabel('Época')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "for i in range(len(history)):\n",
    "  plt.plot(history[i].history['val_loss'])\n",
    "plt.title('Métrica de pérdida')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo del porcentajes de validación \n",
    "\n",
    "best_val_history = []\n",
    "for i in range(1,3):\n",
    "    model = load_model('modelos/transfer_learning_'+str(i)+'.hdf5')\n",
    "    best_val_history.append(model.evaluate(validation_dataset))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de promedios de validación y pérdida \n",
    "\n",
    "prom_loss = 0.0;\n",
    "prom_acc = 0.0;\n",
    "for i in range(len(best_val_history)):\n",
    "    prom_loss = prom_loss + best_val_history[i][0]\n",
    "    prom_acc = prom_acc + best_val_history[i][1]\n",
    "\n",
    "prom_loss = prom_loss / len(best_val_history)\n",
    "prom_acc = prom_acc / len(best_val_history)\n",
    "\n",
    "print(prom_loss)\n",
    "print(prom_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"modelos_tipo\", 'zip', \"modelos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
