{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_TipoVehiculo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "VVSTDkb_EzGG",
        "outputId": "28d134a4-6798-4116-c531-54de90097ef7"
      },
      "source": [
        "!pip install pyunpack\r\n",
        "!pip install patool"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/ca/00c8767568924e5c2209da99b6abdeeed9d11cbae2a713d54d041b092a09/entrypoint2-0.2.3-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: easyprocess, argparse, entrypoint2, pyunpack\n",
            "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.3 pyunpack-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKF7khHPE0aN"
      },
      "source": [
        "#Importación de librerías necesarias\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from pyunpack import Archive\r\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "hrJLW48nLB9i",
        "outputId": "0d277cdb-a0a1-437d-e2ac-3dd9666bd350"
      },
      "source": [
        "#Importamos las librerías de costumbre\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "#Instalamos la librería que nos va a permitir bajar de drive\r\n",
        "!pip install gdown\r\n",
        "import gdown\r\n",
        "#Colocamos la URL del archivo\r\n",
        "url = 'https://drive.google.com/uc?id=1LHK1UqsOZMlF9lFuMeRApw6P5mkkexnM'\r\n",
        "#Colocamos el nombre al archivo donde la información será guardada\r\n",
        "Nombre = 'TipoVehiculo.rar'\r\n",
        "#Lo descargamos\r\n",
        "gdown.download(url,Nombre,quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LHK1UqsOZMlF9lFuMeRApw6P5mkkexnM\n",
            "To: /content/TipoVehiculo.rar\n",
            "349MB [00:03, 98.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TipoVehiculo.rar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXaFyIYE5n9"
      },
      "source": [
        "#Descompresión de las imágenes\r\n",
        "os.mkdir('dataset')\r\n",
        "Archive('TipoVehiculo.rar').extractall('dataset/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi8qp0BaFIAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf5d660-3c75-4fd4-f0d0-a6b9d460abe8"
      },
      "source": [
        "#Se cargan los conjustos de imágenes y se reescalan\r\n",
        "\r\n",
        "train_dir = os.path.join('dataset/TipoVehiculo')\r\n",
        "validation_dir = os.path.join('dataset/TipoVehiculo')\r\n",
        "\r\n",
        "BATCH_SIZE = 15\r\n",
        "IMG_SIZE = (224, 224)\r\n",
        "\r\n",
        "train_dataset = image_dataset_from_directory(train_dir,\r\n",
        "                                             shuffle=True,\r\n",
        "                                             batch_size=BATCH_SIZE,\r\n",
        "                                             image_size=IMG_SIZE,\r\n",
        "                                             label_mode='categorical')\r\n",
        "\r\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  batch_size=BATCH_SIZE,\r\n",
        "                                                  image_size=IMG_SIZE,\r\n",
        "                                                  label_mode='categorical')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17542 files belonging to 8 classes.\n",
            "Found 17542 files belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlAMR8QXFcxH"
      },
      "source": [
        "#Configuración de los conjuntos de datos para mejor el rendimiento en el entrenamiento usando la API tf.data\r\n",
        "\r\n",
        "AUTOTUNE = tf.data.AUTOTUNE\r\n",
        "\r\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\r\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPoDUJz-F4K9"
      },
      "source": [
        "#Usar aumento de datos\r\n",
        "\r\n",
        "data_augmentation = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IItOB-rFdqO"
      },
      "source": [
        "#Cambiar la escala de los valores de píxeles de las imágenes \r\n",
        "\r\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\r\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEuoOQ9UFuTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41c6dc1-8e8c-42ad-ce50-e6cd28227218"
      },
      "source": [
        "# Creación sel modelo base a partir del modelo previamente entrenado MobileNet V2\r\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\r\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\r\n",
        "                                               include_top=False,\r\n",
        "                                               weights='imagenet')\r\n",
        "\r\n",
        "#Congelar la base convolucional\r\n",
        "\r\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zjtBJINFyPs"
      },
      "source": [
        "#Agregar un encabezado de clasificación\r\n",
        "\r\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n",
        "prediction_layer = tf.keras.layers.Dense(8,activation='softmax',kernel_initializer='random_normal',bias_initializer='zeros')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HRoP8sj4cS7"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "def write_json(dataz, filename): \r\n",
        "\twith open(filename,'w') as f: \r\n",
        "\t    json.dump(dataz, f, indent=4) \r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "with open('history.json', 'w') as file:\r\n",
        "    json.dump(data, file, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIwM2E9jF_--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5631c4-5cc5-4ee6-a8af-849d1fef76aa"
      },
      "source": [
        "#Compilar el modelo y entrenarlo\r\n",
        "\r\n",
        "os.mkdir('modelos')\r\n",
        "base_learning_rate = 0.0001\r\n",
        "history = []\r\n",
        "contador = 0\r\n",
        "\r\n",
        "for i in range(1,101):\r\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\r\n",
        "    x = data_augmentation(inputs)\r\n",
        "    x = preprocess_input(x)\r\n",
        "    x = base_model(x, training=False)\r\n",
        "    x = global_average_layer(x)\r\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\r\n",
        "    outputs = prediction_layer(x)\r\n",
        "    model = tf.keras.Model(inputs, outputs)\r\n",
        "    mcp_save = ModelCheckpoint('/content/modelos/transfer_learning_TV_'+str(i)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min',save_weights_only=False)\r\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=base_learning_rate),\r\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "    history.append(model.fit(train_dataset,epochs=100,callbacks=[mcp_save],validation_data=validation_dataset)) \r\n",
        "\r\n",
        "    with open('history.json') as json_file: \r\n",
        "\t    datay = json.load(json_file) \r\n",
        "     \r\n",
        "\t    temp = datay\r\n",
        "\r\n",
        "\t    y = { 'accuracy': history[contador].history['accuracy'],\r\n",
        "            'loss': history[contador].history['val_loss']\r\n",
        "      }        \t\t     \r\n",
        "\r\n",
        "\t    temp.append(y) \r\n",
        "    write_json(datay, 'history.json')  \r\n",
        " \r\n",
        "    contador = contador + 1\r\n",
        "\r\n",
        "    del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1170/1170 [==============================] - 70s 52ms/step - loss: 2.2248 - accuracy: 0.2786 - val_loss: 1.3803 - val_accuracy: 0.5604\n",
            "Epoch 2/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 1.6271 - accuracy: 0.4572 - val_loss: 1.1727 - val_accuracy: 0.6463\n",
            "Epoch 3/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 1.4204 - accuracy: 0.5326 - val_loss: 1.0479 - val_accuracy: 0.6920\n",
            "Epoch 4/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 1.2959 - accuracy: 0.5809 - val_loss: 0.9655 - val_accuracy: 0.7158\n",
            "Epoch 5/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 1.2100 - accuracy: 0.6134 - val_loss: 0.9047 - val_accuracy: 0.7300\n",
            "Epoch 6/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 1.1296 - accuracy: 0.6331 - val_loss: 0.8594 - val_accuracy: 0.7394\n",
            "Epoch 7/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 1.0920 - accuracy: 0.6433 - val_loss: 0.8237 - val_accuracy: 0.7466\n",
            "Epoch 8/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 1.0594 - accuracy: 0.6529 - val_loss: 0.7934 - val_accuracy: 0.7540\n",
            "Epoch 9/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 1.0167 - accuracy: 0.6649 - val_loss: 0.7682 - val_accuracy: 0.7606\n",
            "Epoch 10/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.9954 - accuracy: 0.6697 - val_loss: 0.7458 - val_accuracy: 0.7653\n",
            "Epoch 11/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.9655 - accuracy: 0.6786 - val_loss: 0.7273 - val_accuracy: 0.7704\n",
            "Epoch 12/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.9415 - accuracy: 0.6862 - val_loss: 0.7118 - val_accuracy: 0.7740\n",
            "Epoch 13/100\n",
            "1170/1170 [==============================] - 59s 50ms/step - loss: 0.9219 - accuracy: 0.6934 - val_loss: 0.6960 - val_accuracy: 0.7783\n",
            "Epoch 14/100\n",
            "1170/1170 [==============================] - 59s 50ms/step - loss: 0.9084 - accuracy: 0.6930 - val_loss: 0.6825 - val_accuracy: 0.7823\n",
            "Epoch 15/100\n",
            "1170/1170 [==============================] - 59s 51ms/step - loss: 0.8863 - accuracy: 0.6993 - val_loss: 0.6703 - val_accuracy: 0.7862\n",
            "Epoch 16/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.8752 - accuracy: 0.7085 - val_loss: 0.6595 - val_accuracy: 0.7900\n",
            "Epoch 17/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.8649 - accuracy: 0.7077 - val_loss: 0.6507 - val_accuracy: 0.7922\n",
            "Epoch 18/100\n",
            "1170/1170 [==============================] - 59s 51ms/step - loss: 0.8602 - accuracy: 0.7112 - val_loss: 0.6402 - val_accuracy: 0.7960\n",
            "Epoch 19/100\n",
            "1170/1170 [==============================] - 59s 51ms/step - loss: 0.8411 - accuracy: 0.7154 - val_loss: 0.6321 - val_accuracy: 0.7977\n",
            "Epoch 20/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.8478 - accuracy: 0.7179 - val_loss: 0.6247 - val_accuracy: 0.7992\n",
            "Epoch 21/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.8292 - accuracy: 0.7192 - val_loss: 0.6166 - val_accuracy: 0.8023\n",
            "Epoch 22/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.8283 - accuracy: 0.7169 - val_loss: 0.6103 - val_accuracy: 0.8035\n",
            "Epoch 23/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.8148 - accuracy: 0.7275 - val_loss: 0.6037 - val_accuracy: 0.8058\n",
            "Epoch 24/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.8232 - accuracy: 0.7209 - val_loss: 0.5976 - val_accuracy: 0.8077\n",
            "Epoch 25/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7966 - accuracy: 0.7307 - val_loss: 0.5921 - val_accuracy: 0.8087\n",
            "Epoch 26/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7874 - accuracy: 0.7375 - val_loss: 0.5870 - val_accuracy: 0.8094\n",
            "Epoch 27/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.8045 - accuracy: 0.7259 - val_loss: 0.5821 - val_accuracy: 0.8105\n",
            "Epoch 28/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7877 - accuracy: 0.7299 - val_loss: 0.5779 - val_accuracy: 0.8121\n",
            "Epoch 29/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7802 - accuracy: 0.7382 - val_loss: 0.5726 - val_accuracy: 0.8130\n",
            "Epoch 30/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7882 - accuracy: 0.7399 - val_loss: 0.5692 - val_accuracy: 0.8143\n",
            "Epoch 31/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7700 - accuracy: 0.7384 - val_loss: 0.5650 - val_accuracy: 0.8157\n",
            "Epoch 32/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7719 - accuracy: 0.7336 - val_loss: 0.5616 - val_accuracy: 0.8167\n",
            "Epoch 33/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7656 - accuracy: 0.7440 - val_loss: 0.5578 - val_accuracy: 0.8175\n",
            "Epoch 34/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7483 - accuracy: 0.7462 - val_loss: 0.5541 - val_accuracy: 0.8190\n",
            "Epoch 35/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7473 - accuracy: 0.7453 - val_loss: 0.5511 - val_accuracy: 0.8195\n",
            "Epoch 36/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7467 - accuracy: 0.7467 - val_loss: 0.5481 - val_accuracy: 0.8205\n",
            "Epoch 37/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7467 - accuracy: 0.7435 - val_loss: 0.5445 - val_accuracy: 0.8216\n",
            "Epoch 38/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7475 - accuracy: 0.7470 - val_loss: 0.5417 - val_accuracy: 0.8220\n",
            "Epoch 39/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7371 - accuracy: 0.7470 - val_loss: 0.5385 - val_accuracy: 0.8229\n",
            "Epoch 40/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7468 - accuracy: 0.7470 - val_loss: 0.5356 - val_accuracy: 0.8240\n",
            "Epoch 41/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7372 - accuracy: 0.7462 - val_loss: 0.5334 - val_accuracy: 0.8244\n",
            "Epoch 42/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7319 - accuracy: 0.7509 - val_loss: 0.5308 - val_accuracy: 0.8250\n",
            "Epoch 43/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7297 - accuracy: 0.7540 - val_loss: 0.5290 - val_accuracy: 0.8258\n",
            "Epoch 44/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7212 - accuracy: 0.7522 - val_loss: 0.5263 - val_accuracy: 0.8268\n",
            "Epoch 45/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7201 - accuracy: 0.7552 - val_loss: 0.5236 - val_accuracy: 0.8273\n",
            "Epoch 46/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7237 - accuracy: 0.7581 - val_loss: 0.5215 - val_accuracy: 0.8284\n",
            "Epoch 47/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7147 - accuracy: 0.7589 - val_loss: 0.5196 - val_accuracy: 0.8284\n",
            "Epoch 48/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.7081 - accuracy: 0.7606 - val_loss: 0.5173 - val_accuracy: 0.8289\n",
            "Epoch 49/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7035 - accuracy: 0.7603 - val_loss: 0.5152 - val_accuracy: 0.8297\n",
            "Epoch 50/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.7022 - accuracy: 0.7610 - val_loss: 0.5132 - val_accuracy: 0.8303\n",
            "Epoch 51/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6963 - accuracy: 0.7661 - val_loss: 0.5117 - val_accuracy: 0.8307\n",
            "Epoch 52/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.7022 - accuracy: 0.7589 - val_loss: 0.5103 - val_accuracy: 0.8309\n",
            "Epoch 53/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7124 - accuracy: 0.7581 - val_loss: 0.5085 - val_accuracy: 0.8311\n",
            "Epoch 54/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7003 - accuracy: 0.7648 - val_loss: 0.5063 - val_accuracy: 0.8320\n",
            "Epoch 55/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7024 - accuracy: 0.7597 - val_loss: 0.5053 - val_accuracy: 0.8321\n",
            "Epoch 56/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6929 - accuracy: 0.7661 - val_loss: 0.5034 - val_accuracy: 0.8326\n",
            "Epoch 57/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.7054 - accuracy: 0.7614 - val_loss: 0.5018 - val_accuracy: 0.8331\n",
            "Epoch 58/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6860 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.8337\n",
            "Epoch 59/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6870 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.8338\n",
            "Epoch 60/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6914 - accuracy: 0.7644 - val_loss: 0.4976 - val_accuracy: 0.8339\n",
            "Epoch 61/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6762 - accuracy: 0.7670 - val_loss: 0.4960 - val_accuracy: 0.8349\n",
            "Epoch 62/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6928 - accuracy: 0.7612 - val_loss: 0.4948 - val_accuracy: 0.8348\n",
            "Epoch 63/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6876 - accuracy: 0.7636 - val_loss: 0.4932 - val_accuracy: 0.8355\n",
            "Epoch 64/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6932 - accuracy: 0.7625 - val_loss: 0.4919 - val_accuracy: 0.8357\n",
            "Epoch 65/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6791 - accuracy: 0.7688 - val_loss: 0.4906 - val_accuracy: 0.8362\n",
            "Epoch 66/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6793 - accuracy: 0.7676 - val_loss: 0.4892 - val_accuracy: 0.8364\n",
            "Epoch 67/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6823 - accuracy: 0.7686 - val_loss: 0.4882 - val_accuracy: 0.8367\n",
            "Epoch 68/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6776 - accuracy: 0.7709 - val_loss: 0.4867 - val_accuracy: 0.8367\n",
            "Epoch 69/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6722 - accuracy: 0.7660 - val_loss: 0.4857 - val_accuracy: 0.8371\n",
            "Epoch 70/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6721 - accuracy: 0.7710 - val_loss: 0.4849 - val_accuracy: 0.8374\n",
            "Epoch 71/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6600 - accuracy: 0.7733 - val_loss: 0.4832 - val_accuracy: 0.8376\n",
            "Epoch 72/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6726 - accuracy: 0.7684 - val_loss: 0.4824 - val_accuracy: 0.8380\n",
            "Epoch 73/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6635 - accuracy: 0.7706 - val_loss: 0.4812 - val_accuracy: 0.8384\n",
            "Epoch 74/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6717 - accuracy: 0.7690 - val_loss: 0.4806 - val_accuracy: 0.8386\n",
            "Epoch 75/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6786 - accuracy: 0.7671 - val_loss: 0.4794 - val_accuracy: 0.8390\n",
            "Epoch 76/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6676 - accuracy: 0.7653 - val_loss: 0.4783 - val_accuracy: 0.8398\n",
            "Epoch 77/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6664 - accuracy: 0.7770 - val_loss: 0.4776 - val_accuracy: 0.8399\n",
            "Epoch 78/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6652 - accuracy: 0.7686 - val_loss: 0.4767 - val_accuracy: 0.8399\n",
            "Epoch 79/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6668 - accuracy: 0.7725 - val_loss: 0.4758 - val_accuracy: 0.8402\n",
            "Epoch 80/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6506 - accuracy: 0.7769 - val_loss: 0.4742 - val_accuracy: 0.8403\n",
            "Epoch 81/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6569 - accuracy: 0.7744 - val_loss: 0.4732 - val_accuracy: 0.8407\n",
            "Epoch 82/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6516 - accuracy: 0.7735 - val_loss: 0.4722 - val_accuracy: 0.8403\n",
            "Epoch 83/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6551 - accuracy: 0.7715 - val_loss: 0.4715 - val_accuracy: 0.8411\n",
            "Epoch 84/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6504 - accuracy: 0.7759 - val_loss: 0.4707 - val_accuracy: 0.8410\n",
            "Epoch 85/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6399 - accuracy: 0.7834 - val_loss: 0.4702 - val_accuracy: 0.8418\n",
            "Epoch 86/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.6513 - accuracy: 0.7803 - val_loss: 0.4693 - val_accuracy: 0.8416\n",
            "Epoch 87/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.6600 - accuracy: 0.7740 - val_loss: 0.4681 - val_accuracy: 0.8422\n",
            "Epoch 88/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.6555 - accuracy: 0.7744 - val_loss: 0.4677 - val_accuracy: 0.8421\n",
            "Epoch 89/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6471 - accuracy: 0.7810 - val_loss: 0.4666 - val_accuracy: 0.8428\n",
            "Epoch 90/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6490 - accuracy: 0.7730 - val_loss: 0.4658 - val_accuracy: 0.8426\n",
            "Epoch 91/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6583 - accuracy: 0.7734 - val_loss: 0.4652 - val_accuracy: 0.8429\n",
            "Epoch 92/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6398 - accuracy: 0.7791 - val_loss: 0.4642 - val_accuracy: 0.8438\n",
            "Epoch 93/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6445 - accuracy: 0.7788 - val_loss: 0.4635 - val_accuracy: 0.8435\n",
            "Epoch 94/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6396 - accuracy: 0.7840 - val_loss: 0.4631 - val_accuracy: 0.8433\n",
            "Epoch 95/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6521 - accuracy: 0.7740 - val_loss: 0.4624 - val_accuracy: 0.8434\n",
            "Epoch 96/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6384 - accuracy: 0.7780 - val_loss: 0.4615 - val_accuracy: 0.8441\n",
            "Epoch 97/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6357 - accuracy: 0.7758 - val_loss: 0.4607 - val_accuracy: 0.8445\n",
            "Epoch 98/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6431 - accuracy: 0.7793 - val_loss: 0.4598 - val_accuracy: 0.8447\n",
            "Epoch 99/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6411 - accuracy: 0.7799 - val_loss: 0.4593 - val_accuracy: 0.8445\n",
            "Epoch 100/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6393 - accuracy: 0.7792 - val_loss: 0.4586 - val_accuracy: 0.8449\n",
            "Epoch 1/100\n",
            "1170/1170 [==============================] - 64s 53ms/step - loss: 0.6449 - accuracy: 0.7745 - val_loss: 0.4584 - val_accuracy: 0.8447\n",
            "Epoch 2/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6302 - accuracy: 0.7849 - val_loss: 0.4575 - val_accuracy: 0.8451\n",
            "Epoch 3/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6323 - accuracy: 0.7807 - val_loss: 0.4570 - val_accuracy: 0.8451\n",
            "Epoch 4/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6369 - accuracy: 0.7780 - val_loss: 0.4563 - val_accuracy: 0.8455\n",
            "Epoch 5/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6427 - accuracy: 0.7779 - val_loss: 0.4557 - val_accuracy: 0.8459\n",
            "Epoch 6/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6403 - accuracy: 0.7827 - val_loss: 0.4549 - val_accuracy: 0.8459\n",
            "Epoch 7/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6405 - accuracy: 0.7778 - val_loss: 0.4546 - val_accuracy: 0.8456\n",
            "Epoch 8/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6362 - accuracy: 0.7830 - val_loss: 0.4539 - val_accuracy: 0.8455\n",
            "Epoch 9/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6322 - accuracy: 0.7793 - val_loss: 0.4530 - val_accuracy: 0.8470\n",
            "Epoch 10/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6361 - accuracy: 0.7809 - val_loss: 0.4527 - val_accuracy: 0.8461\n",
            "Epoch 11/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6227 - accuracy: 0.7828 - val_loss: 0.4520 - val_accuracy: 0.8464\n",
            "Epoch 12/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6324 - accuracy: 0.7810 - val_loss: 0.4514 - val_accuracy: 0.8467\n",
            "Epoch 13/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6366 - accuracy: 0.7791 - val_loss: 0.4507 - val_accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6230 - accuracy: 0.7830 - val_loss: 0.4504 - val_accuracy: 0.8472\n",
            "Epoch 15/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6165 - accuracy: 0.7841 - val_loss: 0.4502 - val_accuracy: 0.8468\n",
            "Epoch 16/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6284 - accuracy: 0.7914 - val_loss: 0.4498 - val_accuracy: 0.8468\n",
            "Epoch 17/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6307 - accuracy: 0.7788 - val_loss: 0.4489 - val_accuracy: 0.8473\n",
            "Epoch 18/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6229 - accuracy: 0.7814 - val_loss: 0.4487 - val_accuracy: 0.8476\n",
            "Epoch 19/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6248 - accuracy: 0.7830 - val_loss: 0.4479 - val_accuracy: 0.8478\n",
            "Epoch 20/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6262 - accuracy: 0.7848 - val_loss: 0.4473 - val_accuracy: 0.8482\n",
            "Epoch 21/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6305 - accuracy: 0.7841 - val_loss: 0.4470 - val_accuracy: 0.8480\n",
            "Epoch 22/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6198 - accuracy: 0.7891 - val_loss: 0.4461 - val_accuracy: 0.8484\n",
            "Epoch 23/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6213 - accuracy: 0.7864 - val_loss: 0.4457 - val_accuracy: 0.8489\n",
            "Epoch 24/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6168 - accuracy: 0.7847 - val_loss: 0.4455 - val_accuracy: 0.8482\n",
            "Epoch 25/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6253 - accuracy: 0.7797 - val_loss: 0.4452 - val_accuracy: 0.8489\n",
            "Epoch 26/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6177 - accuracy: 0.7878 - val_loss: 0.4448 - val_accuracy: 0.8492\n",
            "Epoch 27/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6250 - accuracy: 0.7850 - val_loss: 0.4443 - val_accuracy: 0.8490\n",
            "Epoch 28/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6131 - accuracy: 0.7901 - val_loss: 0.4437 - val_accuracy: 0.8490\n",
            "Epoch 29/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6148 - accuracy: 0.7840 - val_loss: 0.4432 - val_accuracy: 0.8493\n",
            "Epoch 30/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6180 - accuracy: 0.7823 - val_loss: 0.4424 - val_accuracy: 0.8498\n",
            "Epoch 31/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6180 - accuracy: 0.7860 - val_loss: 0.4419 - val_accuracy: 0.8496\n",
            "Epoch 32/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6148 - accuracy: 0.7883 - val_loss: 0.4414 - val_accuracy: 0.8496\n",
            "Epoch 33/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6149 - accuracy: 0.7860 - val_loss: 0.4411 - val_accuracy: 0.8502\n",
            "Epoch 34/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6117 - accuracy: 0.7844 - val_loss: 0.4407 - val_accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6115 - accuracy: 0.7908 - val_loss: 0.4405 - val_accuracy: 0.8504\n",
            "Epoch 36/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6127 - accuracy: 0.7880 - val_loss: 0.4399 - val_accuracy: 0.8504\n",
            "Epoch 37/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6123 - accuracy: 0.7870 - val_loss: 0.4394 - val_accuracy: 0.8505\n",
            "Epoch 38/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6150 - accuracy: 0.7847 - val_loss: 0.4389 - val_accuracy: 0.8506\n",
            "Epoch 39/100\n",
            "1170/1170 [==============================] - 60s 52ms/step - loss: 0.6136 - accuracy: 0.7885 - val_loss: 0.4386 - val_accuracy: 0.8506\n",
            "Epoch 40/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6039 - accuracy: 0.7887 - val_loss: 0.4383 - val_accuracy: 0.8506\n",
            "Epoch 41/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6083 - accuracy: 0.7909 - val_loss: 0.4382 - val_accuracy: 0.8509\n",
            "Epoch 42/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6114 - accuracy: 0.7883 - val_loss: 0.4373 - val_accuracy: 0.8514\n",
            "Epoch 43/100\n",
            "1170/1170 [==============================] - 60s 51ms/step - loss: 0.6167 - accuracy: 0.7814 - val_loss: 0.4373 - val_accuracy: 0.8507\n",
            "Epoch 44/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6084 - accuracy: 0.7904 - val_loss: 0.4369 - val_accuracy: 0.8509\n",
            "Epoch 45/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6065 - accuracy: 0.7900 - val_loss: 0.4366 - val_accuracy: 0.8512\n",
            "Epoch 46/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6120 - accuracy: 0.7888 - val_loss: 0.4360 - val_accuracy: 0.8513\n",
            "Epoch 47/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6056 - accuracy: 0.7939 - val_loss: 0.4359 - val_accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5971 - accuracy: 0.7916 - val_loss: 0.4356 - val_accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6100 - accuracy: 0.7844 - val_loss: 0.4358 - val_accuracy: 0.8517\n",
            "Epoch 50/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6043 - accuracy: 0.7909 - val_loss: 0.4350 - val_accuracy: 0.8522\n",
            "Epoch 51/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6066 - accuracy: 0.7877 - val_loss: 0.4346 - val_accuracy: 0.8523\n",
            "Epoch 52/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5991 - accuracy: 0.7924 - val_loss: 0.4341 - val_accuracy: 0.8521\n",
            "Epoch 53/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6158 - accuracy: 0.7883 - val_loss: 0.4342 - val_accuracy: 0.8518\n",
            "Epoch 54/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5986 - accuracy: 0.7918 - val_loss: 0.4335 - val_accuracy: 0.8524\n",
            "Epoch 55/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6073 - accuracy: 0.7929 - val_loss: 0.4335 - val_accuracy: 0.8526\n",
            "Epoch 56/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6118 - accuracy: 0.7868 - val_loss: 0.4331 - val_accuracy: 0.8528\n",
            "Epoch 57/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6025 - accuracy: 0.7915 - val_loss: 0.4327 - val_accuracy: 0.8528\n",
            "Epoch 58/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6034 - accuracy: 0.7879 - val_loss: 0.4325 - val_accuracy: 0.8530\n",
            "Epoch 59/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5946 - accuracy: 0.7934 - val_loss: 0.4324 - val_accuracy: 0.8529\n",
            "Epoch 60/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6054 - accuracy: 0.7917 - val_loss: 0.4316 - val_accuracy: 0.8531\n",
            "Epoch 61/100\n",
            "1170/1170 [==============================] - 62s 52ms/step - loss: 0.5916 - accuracy: 0.7972 - val_loss: 0.4314 - val_accuracy: 0.8536\n",
            "Epoch 62/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5984 - accuracy: 0.7921 - val_loss: 0.4309 - val_accuracy: 0.8540\n",
            "Epoch 63/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5900 - accuracy: 0.7939 - val_loss: 0.4305 - val_accuracy: 0.8532\n",
            "Epoch 64/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6035 - accuracy: 0.7898 - val_loss: 0.4298 - val_accuracy: 0.8529\n",
            "Epoch 65/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6001 - accuracy: 0.7959 - val_loss: 0.4295 - val_accuracy: 0.8530\n",
            "Epoch 66/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6016 - accuracy: 0.7901 - val_loss: 0.4291 - val_accuracy: 0.8532\n",
            "Epoch 67/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5825 - accuracy: 0.7957 - val_loss: 0.4292 - val_accuracy: 0.8534\n",
            "Epoch 68/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6017 - accuracy: 0.7934 - val_loss: 0.4292 - val_accuracy: 0.8538\n",
            "Epoch 69/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5969 - accuracy: 0.7889 - val_loss: 0.4287 - val_accuracy: 0.8536\n",
            "Epoch 70/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5943 - accuracy: 0.7944 - val_loss: 0.4282 - val_accuracy: 0.8543\n",
            "Epoch 71/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5992 - accuracy: 0.7890 - val_loss: 0.4282 - val_accuracy: 0.8537\n",
            "Epoch 72/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5931 - accuracy: 0.7955 - val_loss: 0.4277 - val_accuracy: 0.8545\n",
            "Epoch 73/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5945 - accuracy: 0.7943 - val_loss: 0.4274 - val_accuracy: 0.8542\n",
            "Epoch 74/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.6044 - accuracy: 0.7916 - val_loss: 0.4273 - val_accuracy: 0.8543\n",
            "Epoch 75/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5939 - accuracy: 0.7944 - val_loss: 0.4271 - val_accuracy: 0.8543\n",
            "Epoch 76/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5981 - accuracy: 0.7951 - val_loss: 0.4264 - val_accuracy: 0.8545\n",
            "Epoch 77/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5943 - accuracy: 0.7944 - val_loss: 0.4263 - val_accuracy: 0.8546\n",
            "Epoch 78/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6057 - accuracy: 0.7905 - val_loss: 0.4258 - val_accuracy: 0.8545\n",
            "Epoch 79/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6015 - accuracy: 0.7944 - val_loss: 0.4255 - val_accuracy: 0.8547\n",
            "Epoch 80/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5908 - accuracy: 0.7964 - val_loss: 0.4253 - val_accuracy: 0.8547\n",
            "Epoch 81/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5982 - accuracy: 0.7914 - val_loss: 0.4248 - val_accuracy: 0.8547\n",
            "Epoch 82/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5868 - accuracy: 0.7996 - val_loss: 0.4249 - val_accuracy: 0.8549\n",
            "Epoch 83/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5921 - accuracy: 0.7949 - val_loss: 0.4243 - val_accuracy: 0.8553\n",
            "Epoch 84/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5911 - accuracy: 0.7959 - val_loss: 0.4238 - val_accuracy: 0.8555\n",
            "Epoch 85/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5915 - accuracy: 0.7927 - val_loss: 0.4238 - val_accuracy: 0.8549\n",
            "Epoch 86/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5875 - accuracy: 0.7953 - val_loss: 0.4236 - val_accuracy: 0.8555\n",
            "Epoch 87/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5970 - accuracy: 0.7920 - val_loss: 0.4234 - val_accuracy: 0.8555\n",
            "Epoch 88/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5872 - accuracy: 0.7942 - val_loss: 0.4231 - val_accuracy: 0.8553\n",
            "Epoch 89/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5977 - accuracy: 0.7961 - val_loss: 0.4230 - val_accuracy: 0.8555\n",
            "Epoch 90/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.6013 - accuracy: 0.7884 - val_loss: 0.4230 - val_accuracy: 0.8555\n",
            "Epoch 91/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5854 - accuracy: 0.7930 - val_loss: 0.4222 - val_accuracy: 0.8562\n",
            "Epoch 92/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5909 - accuracy: 0.7987 - val_loss: 0.4221 - val_accuracy: 0.8557\n",
            "Epoch 93/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5852 - accuracy: 0.7959 - val_loss: 0.4221 - val_accuracy: 0.8561\n",
            "Epoch 94/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5823 - accuracy: 0.7951 - val_loss: 0.4218 - val_accuracy: 0.8561\n",
            "Epoch 95/100\n",
            "1170/1170 [==============================] - 62s 52ms/step - loss: 0.5904 - accuracy: 0.7941 - val_loss: 0.4210 - val_accuracy: 0.8565\n",
            "Epoch 96/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5754 - accuracy: 0.7980 - val_loss: 0.4209 - val_accuracy: 0.8560\n",
            "Epoch 97/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5887 - accuracy: 0.7974 - val_loss: 0.4204 - val_accuracy: 0.8566\n",
            "Epoch 98/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5892 - accuracy: 0.7946 - val_loss: 0.4202 - val_accuracy: 0.8561\n",
            "Epoch 99/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5769 - accuracy: 0.8008 - val_loss: 0.4200 - val_accuracy: 0.8569\n",
            "Epoch 100/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5845 - accuracy: 0.7931 - val_loss: 0.4200 - val_accuracy: 0.8563\n",
            "Epoch 1/100\n",
            "1170/1170 [==============================] - 64s 53ms/step - loss: 0.5894 - accuracy: 0.7972 - val_loss: 0.4200 - val_accuracy: 0.8567\n",
            "Epoch 2/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5756 - accuracy: 0.8004 - val_loss: 0.4196 - val_accuracy: 0.8570\n",
            "Epoch 3/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5870 - accuracy: 0.7957 - val_loss: 0.4197 - val_accuracy: 0.8566\n",
            "Epoch 4/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5859 - accuracy: 0.7942 - val_loss: 0.4195 - val_accuracy: 0.8567\n",
            "Epoch 5/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5762 - accuracy: 0.7973 - val_loss: 0.4189 - val_accuracy: 0.8575\n",
            "Epoch 6/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5867 - accuracy: 0.7960 - val_loss: 0.4186 - val_accuracy: 0.8569\n",
            "Epoch 7/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5917 - accuracy: 0.7982 - val_loss: 0.4186 - val_accuracy: 0.8566\n",
            "Epoch 8/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5942 - accuracy: 0.7951 - val_loss: 0.4185 - val_accuracy: 0.8573\n",
            "Epoch 9/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5719 - accuracy: 0.8027 - val_loss: 0.4181 - val_accuracy: 0.8575\n",
            "Epoch 10/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5826 - accuracy: 0.7942 - val_loss: 0.4182 - val_accuracy: 0.8572\n",
            "Epoch 11/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5817 - accuracy: 0.7962 - val_loss: 0.4180 - val_accuracy: 0.8578\n",
            "Epoch 12/100\n",
            "1170/1170 [==============================] - 61s 52ms/step - loss: 0.5907 - accuracy: 0.7939 - val_loss: 0.4177 - val_accuracy: 0.8578\n",
            "Epoch 13/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5863 - accuracy: 0.7996 - val_loss: 0.4178 - val_accuracy: 0.8575\n",
            "Epoch 14/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5823 - accuracy: 0.7991 - val_loss: 0.4174 - val_accuracy: 0.8577\n",
            "Epoch 15/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5793 - accuracy: 0.7978 - val_loss: 0.4169 - val_accuracy: 0.8582\n",
            "Epoch 16/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5849 - accuracy: 0.7983 - val_loss: 0.4167 - val_accuracy: 0.8579\n",
            "Epoch 17/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5719 - accuracy: 0.8011 - val_loss: 0.4164 - val_accuracy: 0.8582\n",
            "Epoch 18/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5825 - accuracy: 0.8003 - val_loss: 0.4158 - val_accuracy: 0.8580\n",
            "Epoch 19/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5776 - accuracy: 0.8015 - val_loss: 0.4162 - val_accuracy: 0.8582\n",
            "Epoch 20/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5823 - accuracy: 0.7955 - val_loss: 0.4159 - val_accuracy: 0.8583\n",
            "Epoch 21/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5746 - accuracy: 0.7990 - val_loss: 0.4158 - val_accuracy: 0.8580\n",
            "Epoch 22/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5820 - accuracy: 0.7990 - val_loss: 0.4159 - val_accuracy: 0.8577\n",
            "Epoch 23/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5726 - accuracy: 0.7975 - val_loss: 0.4156 - val_accuracy: 0.8578\n",
            "Epoch 24/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5715 - accuracy: 0.8009 - val_loss: 0.4154 - val_accuracy: 0.8582\n",
            "Epoch 25/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5852 - accuracy: 0.7984 - val_loss: 0.4153 - val_accuracy: 0.8582\n",
            "Epoch 26/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5846 - accuracy: 0.7979 - val_loss: 0.4151 - val_accuracy: 0.8581\n",
            "Epoch 27/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5794 - accuracy: 0.7980 - val_loss: 0.4148 - val_accuracy: 0.8582\n",
            "Epoch 28/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5767 - accuracy: 0.7993 - val_loss: 0.4143 - val_accuracy: 0.8587\n",
            "Epoch 29/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5709 - accuracy: 0.7988 - val_loss: 0.4141 - val_accuracy: 0.8583\n",
            "Epoch 30/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5772 - accuracy: 0.8026 - val_loss: 0.4141 - val_accuracy: 0.8585\n",
            "Epoch 31/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5809 - accuracy: 0.8013 - val_loss: 0.4135 - val_accuracy: 0.8590\n",
            "Epoch 32/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5717 - accuracy: 0.8007 - val_loss: 0.4132 - val_accuracy: 0.8587\n",
            "Epoch 33/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5792 - accuracy: 0.7973 - val_loss: 0.4132 - val_accuracy: 0.8590\n",
            "Epoch 34/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5657 - accuracy: 0.8013 - val_loss: 0.4131 - val_accuracy: 0.8594\n",
            "Epoch 35/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5673 - accuracy: 0.8016 - val_loss: 0.4127 - val_accuracy: 0.8594\n",
            "Epoch 36/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5785 - accuracy: 0.8022 - val_loss: 0.4125 - val_accuracy: 0.8595\n",
            "Epoch 37/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5736 - accuracy: 0.8023 - val_loss: 0.4123 - val_accuracy: 0.8591\n",
            "Epoch 38/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5674 - accuracy: 0.8013 - val_loss: 0.4123 - val_accuracy: 0.8595\n",
            "Epoch 39/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5774 - accuracy: 0.7966 - val_loss: 0.4122 - val_accuracy: 0.8593\n",
            "Epoch 40/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5747 - accuracy: 0.7972 - val_loss: 0.4120 - val_accuracy: 0.8598\n",
            "Epoch 41/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5785 - accuracy: 0.8001 - val_loss: 0.4119 - val_accuracy: 0.8589\n",
            "Epoch 42/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5680 - accuracy: 0.8027 - val_loss: 0.4123 - val_accuracy: 0.8591\n",
            "Epoch 43/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5842 - accuracy: 0.7926 - val_loss: 0.4117 - val_accuracy: 0.8598\n",
            "Epoch 44/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5768 - accuracy: 0.7990 - val_loss: 0.4117 - val_accuracy: 0.8595\n",
            "Epoch 45/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5748 - accuracy: 0.7972 - val_loss: 0.4115 - val_accuracy: 0.8599\n",
            "Epoch 46/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5739 - accuracy: 0.8014 - val_loss: 0.4114 - val_accuracy: 0.8596\n",
            "Epoch 47/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5733 - accuracy: 0.8019 - val_loss: 0.4109 - val_accuracy: 0.8597\n",
            "Epoch 48/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5722 - accuracy: 0.7982 - val_loss: 0.4107 - val_accuracy: 0.8597\n",
            "Epoch 49/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5731 - accuracy: 0.7967 - val_loss: 0.4104 - val_accuracy: 0.8599\n",
            "Epoch 50/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5762 - accuracy: 0.7937 - val_loss: 0.4101 - val_accuracy: 0.8599\n",
            "Epoch 51/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5772 - accuracy: 0.8009 - val_loss: 0.4099 - val_accuracy: 0.8603\n",
            "Epoch 52/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5758 - accuracy: 0.8003 - val_loss: 0.4098 - val_accuracy: 0.8602\n",
            "Epoch 53/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5714 - accuracy: 0.7987 - val_loss: 0.4100 - val_accuracy: 0.8597\n",
            "Epoch 54/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5696 - accuracy: 0.8007 - val_loss: 0.4097 - val_accuracy: 0.8601\n",
            "Epoch 55/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5775 - accuracy: 0.7993 - val_loss: 0.4095 - val_accuracy: 0.8604\n",
            "Epoch 56/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5733 - accuracy: 0.8030 - val_loss: 0.4093 - val_accuracy: 0.8603\n",
            "Epoch 57/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5795 - accuracy: 0.7988 - val_loss: 0.4092 - val_accuracy: 0.8607\n",
            "Epoch 58/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5579 - accuracy: 0.8072 - val_loss: 0.4089 - val_accuracy: 0.8606\n",
            "Epoch 59/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5800 - accuracy: 0.7972 - val_loss: 0.4088 - val_accuracy: 0.8606\n",
            "Epoch 60/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5638 - accuracy: 0.8053 - val_loss: 0.4085 - val_accuracy: 0.8608\n",
            "Epoch 61/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5743 - accuracy: 0.7954 - val_loss: 0.4084 - val_accuracy: 0.8606\n",
            "Epoch 62/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5699 - accuracy: 0.7983 - val_loss: 0.4085 - val_accuracy: 0.8604\n",
            "Epoch 63/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5705 - accuracy: 0.8032 - val_loss: 0.4082 - val_accuracy: 0.8604\n",
            "Epoch 64/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5681 - accuracy: 0.8041 - val_loss: 0.4080 - val_accuracy: 0.8608\n",
            "Epoch 65/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5594 - accuracy: 0.8086 - val_loss: 0.4080 - val_accuracy: 0.8610\n",
            "Epoch 66/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5615 - accuracy: 0.8047 - val_loss: 0.4080 - val_accuracy: 0.8605\n",
            "Epoch 67/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5759 - accuracy: 0.7990 - val_loss: 0.4076 - val_accuracy: 0.8605\n",
            "Epoch 68/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5629 - accuracy: 0.8004 - val_loss: 0.4074 - val_accuracy: 0.8609\n",
            "Epoch 69/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5730 - accuracy: 0.8016 - val_loss: 0.4078 - val_accuracy: 0.8611\n",
            "Epoch 70/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5692 - accuracy: 0.8045 - val_loss: 0.4072 - val_accuracy: 0.8607\n",
            "Epoch 71/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5606 - accuracy: 0.8030 - val_loss: 0.4071 - val_accuracy: 0.8609\n",
            "Epoch 72/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5688 - accuracy: 0.8003 - val_loss: 0.4070 - val_accuracy: 0.8610\n",
            "Epoch 73/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5628 - accuracy: 0.7999 - val_loss: 0.4069 - val_accuracy: 0.8610\n",
            "Epoch 74/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5590 - accuracy: 0.8050 - val_loss: 0.4066 - val_accuracy: 0.8609\n",
            "Epoch 75/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5717 - accuracy: 0.7973 - val_loss: 0.4063 - val_accuracy: 0.8609\n",
            "Epoch 76/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5656 - accuracy: 0.8014 - val_loss: 0.4061 - val_accuracy: 0.8605\n",
            "Epoch 77/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5695 - accuracy: 0.8015 - val_loss: 0.4064 - val_accuracy: 0.8611\n",
            "Epoch 78/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5583 - accuracy: 0.8095 - val_loss: 0.4060 - val_accuracy: 0.8608\n",
            "Epoch 79/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5654 - accuracy: 0.8050 - val_loss: 0.4057 - val_accuracy: 0.8608\n",
            "Epoch 80/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5686 - accuracy: 0.8029 - val_loss: 0.4054 - val_accuracy: 0.8612\n",
            "Epoch 81/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5736 - accuracy: 0.7991 - val_loss: 0.4053 - val_accuracy: 0.8612\n",
            "Epoch 82/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5594 - accuracy: 0.8037 - val_loss: 0.4053 - val_accuracy: 0.8610\n",
            "Epoch 83/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5575 - accuracy: 0.8092 - val_loss: 0.4053 - val_accuracy: 0.8615\n",
            "Epoch 84/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5562 - accuracy: 0.8078 - val_loss: 0.4050 - val_accuracy: 0.8614\n",
            "Epoch 85/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5659 - accuracy: 0.7996 - val_loss: 0.4049 - val_accuracy: 0.8611\n",
            "Epoch 86/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5496 - accuracy: 0.8077 - val_loss: 0.4045 - val_accuracy: 0.8613\n",
            "Epoch 87/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5683 - accuracy: 0.8031 - val_loss: 0.4043 - val_accuracy: 0.8618\n",
            "Epoch 88/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5664 - accuracy: 0.8020 - val_loss: 0.4044 - val_accuracy: 0.8614\n",
            "Epoch 89/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5543 - accuracy: 0.8048 - val_loss: 0.4041 - val_accuracy: 0.8616\n",
            "Epoch 90/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5636 - accuracy: 0.8014 - val_loss: 0.4041 - val_accuracy: 0.8614\n",
            "Epoch 91/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5631 - accuracy: 0.8068 - val_loss: 0.4042 - val_accuracy: 0.8611\n",
            "Epoch 92/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5572 - accuracy: 0.8044 - val_loss: 0.4041 - val_accuracy: 0.8616\n",
            "Epoch 93/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5600 - accuracy: 0.8017 - val_loss: 0.4042 - val_accuracy: 0.8617\n",
            "Epoch 94/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5543 - accuracy: 0.8039 - val_loss: 0.4039 - val_accuracy: 0.8614\n",
            "Epoch 95/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5592 - accuracy: 0.8032 - val_loss: 0.4037 - val_accuracy: 0.8618\n",
            "Epoch 96/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5692 - accuracy: 0.8026 - val_loss: 0.4034 - val_accuracy: 0.8615\n",
            "Epoch 97/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5606 - accuracy: 0.8054 - val_loss: 0.4030 - val_accuracy: 0.8616\n",
            "Epoch 98/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5697 - accuracy: 0.7989 - val_loss: 0.4029 - val_accuracy: 0.8620\n",
            "Epoch 99/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5647 - accuracy: 0.8035 - val_loss: 0.4031 - val_accuracy: 0.8618\n",
            "Epoch 100/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5594 - accuracy: 0.8068 - val_loss: 0.4029 - val_accuracy: 0.8622\n",
            "Epoch 1/100\n",
            "1170/1170 [==============================] - 65s 54ms/step - loss: 0.5660 - accuracy: 0.7974 - val_loss: 0.4029 - val_accuracy: 0.8620\n",
            "Epoch 2/100\n",
            "1170/1170 [==============================] - 62s 53ms/step - loss: 0.5575 - accuracy: 0.8033 - val_loss: 0.4030 - val_accuracy: 0.8615\n",
            "Epoch 3/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5569 - accuracy: 0.8071 - val_loss: 0.4028 - val_accuracy: 0.8622\n",
            "Epoch 4/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5532 - accuracy: 0.8093 - val_loss: 0.4028 - val_accuracy: 0.8623\n",
            "Epoch 5/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5687 - accuracy: 0.8046 - val_loss: 0.4028 - val_accuracy: 0.8622\n",
            "Epoch 6/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5605 - accuracy: 0.8050 - val_loss: 0.4025 - val_accuracy: 0.8622\n",
            "Epoch 7/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5520 - accuracy: 0.8067 - val_loss: 0.4021 - val_accuracy: 0.8624\n",
            "Epoch 8/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5586 - accuracy: 0.8067 - val_loss: 0.4020 - val_accuracy: 0.8618\n",
            "Epoch 9/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5606 - accuracy: 0.8031 - val_loss: 0.4019 - val_accuracy: 0.8622\n",
            "Epoch 10/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5632 - accuracy: 0.8040 - val_loss: 0.4016 - val_accuracy: 0.8624\n",
            "Epoch 11/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5547 - accuracy: 0.8103 - val_loss: 0.4014 - val_accuracy: 0.8624\n",
            "Epoch 12/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5532 - accuracy: 0.8087 - val_loss: 0.4014 - val_accuracy: 0.8626\n",
            "Epoch 13/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5569 - accuracy: 0.8012 - val_loss: 0.4013 - val_accuracy: 0.8625\n",
            "Epoch 14/100\n",
            "1170/1170 [==============================] - 63s 53ms/step - loss: 0.5583 - accuracy: 0.8063 - val_loss: 0.4012 - val_accuracy: 0.8625\n",
            "Epoch 15/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5554 - accuracy: 0.8077 - val_loss: 0.4012 - val_accuracy: 0.8627\n",
            "Epoch 16/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5648 - accuracy: 0.8017 - val_loss: 0.4013 - val_accuracy: 0.8624\n",
            "Epoch 17/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5579 - accuracy: 0.8055 - val_loss: 0.4009 - val_accuracy: 0.8623\n",
            "Epoch 18/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5573 - accuracy: 0.8095 - val_loss: 0.4012 - val_accuracy: 0.8622\n",
            "Epoch 19/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5540 - accuracy: 0.8043 - val_loss: 0.4009 - val_accuracy: 0.8629\n",
            "Epoch 20/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5667 - accuracy: 0.8030 - val_loss: 0.4009 - val_accuracy: 0.8626\n",
            "Epoch 21/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5571 - accuracy: 0.8066 - val_loss: 0.4008 - val_accuracy: 0.8622\n",
            "Epoch 22/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5455 - accuracy: 0.8100 - val_loss: 0.4006 - val_accuracy: 0.8626\n",
            "Epoch 23/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5521 - accuracy: 0.8120 - val_loss: 0.4006 - val_accuracy: 0.8624\n",
            "Epoch 24/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5618 - accuracy: 0.8055 - val_loss: 0.4004 - val_accuracy: 0.8623\n",
            "Epoch 25/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5519 - accuracy: 0.8066 - val_loss: 0.3998 - val_accuracy: 0.8629\n",
            "Epoch 26/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5509 - accuracy: 0.8117 - val_loss: 0.3999 - val_accuracy: 0.8630\n",
            "Epoch 27/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5594 - accuracy: 0.8024 - val_loss: 0.4000 - val_accuracy: 0.8631\n",
            "Epoch 28/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5568 - accuracy: 0.8046 - val_loss: 0.3999 - val_accuracy: 0.8627\n",
            "Epoch 29/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5634 - accuracy: 0.8046 - val_loss: 0.3998 - val_accuracy: 0.8629\n",
            "Epoch 30/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5635 - accuracy: 0.7998 - val_loss: 0.3996 - val_accuracy: 0.8623\n",
            "Epoch 31/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5537 - accuracy: 0.8019 - val_loss: 0.3998 - val_accuracy: 0.8631\n",
            "Epoch 32/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5521 - accuracy: 0.8053 - val_loss: 0.3996 - val_accuracy: 0.8627\n",
            "Epoch 33/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5534 - accuracy: 0.8043 - val_loss: 0.3993 - val_accuracy: 0.8631\n",
            "Epoch 34/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5524 - accuracy: 0.8048 - val_loss: 0.3992 - val_accuracy: 0.8630\n",
            "Epoch 35/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5491 - accuracy: 0.8060 - val_loss: 0.3995 - val_accuracy: 0.8631\n",
            "Epoch 36/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5436 - accuracy: 0.8089 - val_loss: 0.3993 - val_accuracy: 0.8631\n",
            "Epoch 37/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5472 - accuracy: 0.8038 - val_loss: 0.3992 - val_accuracy: 0.8631\n",
            "Epoch 38/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5538 - accuracy: 0.8058 - val_loss: 0.3990 - val_accuracy: 0.8632\n",
            "Epoch 39/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5559 - accuracy: 0.8045 - val_loss: 0.3990 - val_accuracy: 0.8634\n",
            "Epoch 40/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5607 - accuracy: 0.8015 - val_loss: 0.3986 - val_accuracy: 0.8632\n",
            "Epoch 41/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5532 - accuracy: 0.8078 - val_loss: 0.3987 - val_accuracy: 0.8635\n",
            "Epoch 42/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5494 - accuracy: 0.8073 - val_loss: 0.3986 - val_accuracy: 0.8629\n",
            "Epoch 43/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5566 - accuracy: 0.8055 - val_loss: 0.3983 - val_accuracy: 0.8633\n",
            "Epoch 44/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5550 - accuracy: 0.7999 - val_loss: 0.3982 - val_accuracy: 0.8630\n",
            "Epoch 45/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5674 - accuracy: 0.8026 - val_loss: 0.3982 - val_accuracy: 0.8631\n",
            "Epoch 46/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5565 - accuracy: 0.8050 - val_loss: 0.3980 - val_accuracy: 0.8630\n",
            "Epoch 47/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5609 - accuracy: 0.8015 - val_loss: 0.3979 - val_accuracy: 0.8632\n",
            "Epoch 48/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5512 - accuracy: 0.8085 - val_loss: 0.3977 - val_accuracy: 0.8632\n",
            "Epoch 49/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5573 - accuracy: 0.8079 - val_loss: 0.3975 - val_accuracy: 0.8639\n",
            "Epoch 50/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5530 - accuracy: 0.8060 - val_loss: 0.3972 - val_accuracy: 0.8641\n",
            "Epoch 51/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5447 - accuracy: 0.8095 - val_loss: 0.3971 - val_accuracy: 0.8642\n",
            "Epoch 52/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5502 - accuracy: 0.8091 - val_loss: 0.3968 - val_accuracy: 0.8639\n",
            "Epoch 53/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5595 - accuracy: 0.8053 - val_loss: 0.3969 - val_accuracy: 0.8642\n",
            "Epoch 54/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5482 - accuracy: 0.8093 - val_loss: 0.3970 - val_accuracy: 0.8641\n",
            "Epoch 55/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5539 - accuracy: 0.8077 - val_loss: 0.3968 - val_accuracy: 0.8646\n",
            "Epoch 56/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5522 - accuracy: 0.8028 - val_loss: 0.3968 - val_accuracy: 0.8640\n",
            "Epoch 57/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5520 - accuracy: 0.8091 - val_loss: 0.3969 - val_accuracy: 0.8642\n",
            "Epoch 58/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5495 - accuracy: 0.8081 - val_loss: 0.3967 - val_accuracy: 0.8640\n",
            "Epoch 59/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5566 - accuracy: 0.8068 - val_loss: 0.3967 - val_accuracy: 0.8640\n",
            "Epoch 60/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5471 - accuracy: 0.8058 - val_loss: 0.3967 - val_accuracy: 0.8640\n",
            "Epoch 61/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5550 - accuracy: 0.8087 - val_loss: 0.3966 - val_accuracy: 0.8642\n",
            "Epoch 62/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5541 - accuracy: 0.8053 - val_loss: 0.3963 - val_accuracy: 0.8646\n",
            "Epoch 63/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5503 - accuracy: 0.8111 - val_loss: 0.3962 - val_accuracy: 0.8644\n",
            "Epoch 64/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5485 - accuracy: 0.8056 - val_loss: 0.3959 - val_accuracy: 0.8639\n",
            "Epoch 65/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5565 - accuracy: 0.8085 - val_loss: 0.3958 - val_accuracy: 0.8645\n",
            "Epoch 66/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5499 - accuracy: 0.8067 - val_loss: 0.3960 - val_accuracy: 0.8647\n",
            "Epoch 67/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5482 - accuracy: 0.8113 - val_loss: 0.3958 - val_accuracy: 0.8643\n",
            "Epoch 68/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5464 - accuracy: 0.8087 - val_loss: 0.3956 - val_accuracy: 0.8643\n",
            "Epoch 69/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5386 - accuracy: 0.8093 - val_loss: 0.3954 - val_accuracy: 0.8645\n",
            "Epoch 70/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5502 - accuracy: 0.8066 - val_loss: 0.3956 - val_accuracy: 0.8644\n",
            "Epoch 71/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5490 - accuracy: 0.8076 - val_loss: 0.3952 - val_accuracy: 0.8650\n",
            "Epoch 72/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5497 - accuracy: 0.8130 - val_loss: 0.3953 - val_accuracy: 0.8648\n",
            "Epoch 73/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5491 - accuracy: 0.8087 - val_loss: 0.3954 - val_accuracy: 0.8646\n",
            "Epoch 74/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5478 - accuracy: 0.8052 - val_loss: 0.3952 - val_accuracy: 0.8649\n",
            "Epoch 75/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5519 - accuracy: 0.8057 - val_loss: 0.3950 - val_accuracy: 0.8652\n",
            "Epoch 76/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5400 - accuracy: 0.8118 - val_loss: 0.3950 - val_accuracy: 0.8649\n",
            "Epoch 77/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5417 - accuracy: 0.8100 - val_loss: 0.3949 - val_accuracy: 0.8648\n",
            "Epoch 78/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5460 - accuracy: 0.8072 - val_loss: 0.3947 - val_accuracy: 0.8648\n",
            "Epoch 79/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5441 - accuracy: 0.8087 - val_loss: 0.3945 - val_accuracy: 0.8651\n",
            "Epoch 80/100\n",
            "1170/1170 [==============================] - 67s 58ms/step - loss: 0.5477 - accuracy: 0.8111 - val_loss: 0.3946 - val_accuracy: 0.8650\n",
            "Epoch 81/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5506 - accuracy: 0.8037 - val_loss: 0.3946 - val_accuracy: 0.8647\n",
            "Epoch 82/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5452 - accuracy: 0.8083 - val_loss: 0.3946 - val_accuracy: 0.8650\n",
            "Epoch 83/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5484 - accuracy: 0.8103 - val_loss: 0.3944 - val_accuracy: 0.8651\n",
            "Epoch 84/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5377 - accuracy: 0.8123 - val_loss: 0.3941 - val_accuracy: 0.8650\n",
            "Epoch 85/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5494 - accuracy: 0.8041 - val_loss: 0.3942 - val_accuracy: 0.8653\n",
            "Epoch 86/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5483 - accuracy: 0.8042 - val_loss: 0.3941 - val_accuracy: 0.8651\n",
            "Epoch 87/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5406 - accuracy: 0.8070 - val_loss: 0.3938 - val_accuracy: 0.8655\n",
            "Epoch 88/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5521 - accuracy: 0.8074 - val_loss: 0.3940 - val_accuracy: 0.8652\n",
            "Epoch 89/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5433 - accuracy: 0.8108 - val_loss: 0.3938 - val_accuracy: 0.8657\n",
            "Epoch 90/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5438 - accuracy: 0.8085 - val_loss: 0.3938 - val_accuracy: 0.8651\n",
            "Epoch 91/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5490 - accuracy: 0.8070 - val_loss: 0.3937 - val_accuracy: 0.8655\n",
            "Epoch 92/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5513 - accuracy: 0.8118 - val_loss: 0.3938 - val_accuracy: 0.8652\n",
            "Epoch 93/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5477 - accuracy: 0.8070 - val_loss: 0.3936 - val_accuracy: 0.8658\n",
            "Epoch 94/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5487 - accuracy: 0.8112 - val_loss: 0.3937 - val_accuracy: 0.8656\n",
            "Epoch 95/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5474 - accuracy: 0.8062 - val_loss: 0.3936 - val_accuracy: 0.8656\n",
            "Epoch 96/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5446 - accuracy: 0.8066 - val_loss: 0.3937 - val_accuracy: 0.8655\n",
            "Epoch 97/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5436 - accuracy: 0.8082 - val_loss: 0.3935 - val_accuracy: 0.8656\n",
            "Epoch 98/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5409 - accuracy: 0.8116 - val_loss: 0.3934 - val_accuracy: 0.8655\n",
            "Epoch 99/100\n",
            "1170/1170 [==============================] - 63s 54ms/step - loss: 0.5516 - accuracy: 0.8078 - val_loss: 0.3933 - val_accuracy: 0.8655\n",
            "Epoch 100/100\n",
            "1170/1170 [==============================] - 64s 54ms/step - loss: 0.5445 - accuracy: 0.8063 - val_loss: 0.3931 - val_accuracy: 0.8659\n",
            "Epoch 1/100\n",
            "1170/1170 [==============================] - 67s 55ms/step - loss: 0.5574 - accuracy: 0.8079 - val_loss: 0.3930 - val_accuracy: 0.8652\n",
            "Epoch 2/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5541 - accuracy: 0.8089 - val_loss: 0.3930 - val_accuracy: 0.8655\n",
            "Epoch 3/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5499 - accuracy: 0.8072 - val_loss: 0.3931 - val_accuracy: 0.8654\n",
            "Epoch 4/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5447 - accuracy: 0.8104 - val_loss: 0.3930 - val_accuracy: 0.8654\n",
            "Epoch 5/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5467 - accuracy: 0.8096 - val_loss: 0.3927 - val_accuracy: 0.8658\n",
            "Epoch 6/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5441 - accuracy: 0.8107 - val_loss: 0.3930 - val_accuracy: 0.8654\n",
            "Epoch 7/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5475 - accuracy: 0.8092 - val_loss: 0.3929 - val_accuracy: 0.8655\n",
            "Epoch 8/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5380 - accuracy: 0.8083 - val_loss: 0.3924 - val_accuracy: 0.8656\n",
            "Epoch 9/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5308 - accuracy: 0.8193 - val_loss: 0.3923 - val_accuracy: 0.8656\n",
            "Epoch 10/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5376 - accuracy: 0.8116 - val_loss: 0.3924 - val_accuracy: 0.8658\n",
            "Epoch 11/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5499 - accuracy: 0.8027 - val_loss: 0.3927 - val_accuracy: 0.8653\n",
            "Epoch 12/100\n",
            "1170/1170 [==============================] - 65s 56ms/step - loss: 0.5449 - accuracy: 0.8084 - val_loss: 0.3926 - val_accuracy: 0.8650\n",
            "Epoch 13/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5424 - accuracy: 0.8120 - val_loss: 0.3921 - val_accuracy: 0.8660\n",
            "Epoch 14/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5332 - accuracy: 0.8118 - val_loss: 0.3919 - val_accuracy: 0.8656\n",
            "Epoch 15/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5415 - accuracy: 0.8094 - val_loss: 0.3923 - val_accuracy: 0.8653\n",
            "Epoch 16/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5432 - accuracy: 0.8085 - val_loss: 0.3921 - val_accuracy: 0.8657\n",
            "Epoch 17/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5430 - accuracy: 0.8108 - val_loss: 0.3922 - val_accuracy: 0.8655\n",
            "Epoch 18/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5461 - accuracy: 0.8072 - val_loss: 0.3917 - val_accuracy: 0.8661\n",
            "Epoch 19/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5457 - accuracy: 0.8096 - val_loss: 0.3920 - val_accuracy: 0.8655\n",
            "Epoch 20/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5302 - accuracy: 0.8111 - val_loss: 0.3918 - val_accuracy: 0.8662\n",
            "Epoch 21/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5466 - accuracy: 0.8127 - val_loss: 0.3918 - val_accuracy: 0.8660\n",
            "Epoch 22/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5395 - accuracy: 0.8112 - val_loss: 0.3915 - val_accuracy: 0.8662\n",
            "Epoch 23/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5418 - accuracy: 0.8072 - val_loss: 0.3912 - val_accuracy: 0.8665\n",
            "Epoch 24/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5484 - accuracy: 0.8068 - val_loss: 0.3911 - val_accuracy: 0.8660\n",
            "Epoch 25/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5464 - accuracy: 0.8068 - val_loss: 0.3910 - val_accuracy: 0.8660\n",
            "Epoch 26/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5428 - accuracy: 0.8111 - val_loss: 0.3911 - val_accuracy: 0.8661\n",
            "Epoch 27/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5487 - accuracy: 0.8074 - val_loss: 0.3912 - val_accuracy: 0.8661\n",
            "Epoch 28/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5374 - accuracy: 0.8104 - val_loss: 0.3911 - val_accuracy: 0.8661\n",
            "Epoch 29/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5365 - accuracy: 0.8123 - val_loss: 0.3908 - val_accuracy: 0.8664\n",
            "Epoch 30/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5439 - accuracy: 0.8106 - val_loss: 0.3912 - val_accuracy: 0.8662\n",
            "Epoch 31/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5325 - accuracy: 0.8086 - val_loss: 0.3909 - val_accuracy: 0.8661\n",
            "Epoch 32/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5367 - accuracy: 0.8120 - val_loss: 0.3907 - val_accuracy: 0.8658\n",
            "Epoch 33/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5440 - accuracy: 0.8067 - val_loss: 0.3905 - val_accuracy: 0.8661\n",
            "Epoch 34/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5408 - accuracy: 0.8076 - val_loss: 0.3903 - val_accuracy: 0.8663\n",
            "Epoch 35/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5284 - accuracy: 0.8142 - val_loss: 0.3905 - val_accuracy: 0.8659\n",
            "Epoch 36/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5370 - accuracy: 0.8108 - val_loss: 0.3904 - val_accuracy: 0.8662\n",
            "Epoch 37/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5393 - accuracy: 0.8120 - val_loss: 0.3906 - val_accuracy: 0.8656\n",
            "Epoch 38/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5455 - accuracy: 0.8064 - val_loss: 0.3903 - val_accuracy: 0.8661\n",
            "Epoch 39/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5345 - accuracy: 0.8097 - val_loss: 0.3899 - val_accuracy: 0.8665\n",
            "Epoch 40/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5436 - accuracy: 0.8063 - val_loss: 0.3902 - val_accuracy: 0.8660\n",
            "Epoch 41/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5384 - accuracy: 0.8119 - val_loss: 0.3900 - val_accuracy: 0.8665\n",
            "Epoch 42/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5401 - accuracy: 0.8093 - val_loss: 0.3899 - val_accuracy: 0.8665\n",
            "Epoch 43/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5426 - accuracy: 0.8142 - val_loss: 0.3901 - val_accuracy: 0.8658\n",
            "Epoch 44/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5474 - accuracy: 0.8093 - val_loss: 0.3900 - val_accuracy: 0.8660\n",
            "Epoch 45/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5402 - accuracy: 0.8128 - val_loss: 0.3896 - val_accuracy: 0.8666\n",
            "Epoch 46/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5385 - accuracy: 0.8116 - val_loss: 0.3896 - val_accuracy: 0.8665\n",
            "Epoch 47/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5459 - accuracy: 0.8085 - val_loss: 0.3897 - val_accuracy: 0.8663\n",
            "Epoch 48/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5408 - accuracy: 0.8085 - val_loss: 0.3896 - val_accuracy: 0.8659\n",
            "Epoch 49/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5417 - accuracy: 0.8110 - val_loss: 0.3895 - val_accuracy: 0.8664\n",
            "Epoch 50/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5334 - accuracy: 0.8123 - val_loss: 0.3896 - val_accuracy: 0.8657\n",
            "Epoch 51/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5411 - accuracy: 0.8120 - val_loss: 0.3894 - val_accuracy: 0.8664\n",
            "Epoch 52/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5348 - accuracy: 0.8098 - val_loss: 0.3894 - val_accuracy: 0.8658\n",
            "Epoch 53/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5390 - accuracy: 0.8078 - val_loss: 0.3893 - val_accuracy: 0.8663\n",
            "Epoch 54/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5420 - accuracy: 0.8101 - val_loss: 0.3894 - val_accuracy: 0.8665\n",
            "Epoch 55/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5439 - accuracy: 0.8066 - val_loss: 0.3891 - val_accuracy: 0.8669\n",
            "Epoch 56/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5399 - accuracy: 0.8132 - val_loss: 0.3891 - val_accuracy: 0.8669\n",
            "Epoch 57/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5450 - accuracy: 0.8092 - val_loss: 0.3891 - val_accuracy: 0.8667\n",
            "Epoch 58/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5344 - accuracy: 0.8140 - val_loss: 0.3891 - val_accuracy: 0.8669\n",
            "Epoch 59/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5352 - accuracy: 0.8114 - val_loss: 0.3893 - val_accuracy: 0.8669\n",
            "Epoch 60/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5413 - accuracy: 0.8101 - val_loss: 0.3894 - val_accuracy: 0.8658\n",
            "Epoch 61/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5420 - accuracy: 0.8113 - val_loss: 0.3890 - val_accuracy: 0.8669\n",
            "Epoch 62/100\n",
            "1170/1170 [==============================] - 69s 59ms/step - loss: 0.5311 - accuracy: 0.8119 - val_loss: 0.3891 - val_accuracy: 0.8666\n",
            "Epoch 63/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5351 - accuracy: 0.8106 - val_loss: 0.3891 - val_accuracy: 0.8666\n",
            "Epoch 64/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5303 - accuracy: 0.8151 - val_loss: 0.3886 - val_accuracy: 0.8667\n",
            "Epoch 65/100\n",
            "1170/1170 [==============================] - 69s 59ms/step - loss: 0.5320 - accuracy: 0.8130 - val_loss: 0.3887 - val_accuracy: 0.8666\n",
            "Epoch 66/100\n",
            "1170/1170 [==============================] - 68s 58ms/step - loss: 0.5422 - accuracy: 0.8076 - val_loss: 0.3884 - val_accuracy: 0.8667\n",
            "Epoch 67/100\n",
            "1170/1170 [==============================] - 67s 58ms/step - loss: 0.5402 - accuracy: 0.8129 - val_loss: 0.3887 - val_accuracy: 0.8665\n",
            "Epoch 68/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5335 - accuracy: 0.8117 - val_loss: 0.3886 - val_accuracy: 0.8665\n",
            "Epoch 69/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5408 - accuracy: 0.8116 - val_loss: 0.3884 - val_accuracy: 0.8667\n",
            "Epoch 70/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5428 - accuracy: 0.8081 - val_loss: 0.3884 - val_accuracy: 0.8671\n",
            "Epoch 71/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5376 - accuracy: 0.8114 - val_loss: 0.3883 - val_accuracy: 0.8668\n",
            "Epoch 72/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5390 - accuracy: 0.8106 - val_loss: 0.3885 - val_accuracy: 0.8668\n",
            "Epoch 73/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5384 - accuracy: 0.8144 - val_loss: 0.3886 - val_accuracy: 0.8665\n",
            "Epoch 74/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5327 - accuracy: 0.8124 - val_loss: 0.3882 - val_accuracy: 0.8672\n",
            "Epoch 75/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5424 - accuracy: 0.8093 - val_loss: 0.3880 - val_accuracy: 0.8672\n",
            "Epoch 76/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5334 - accuracy: 0.8145 - val_loss: 0.3876 - val_accuracy: 0.8673\n",
            "Epoch 77/100\n",
            "1170/1170 [==============================] - 64s 55ms/step - loss: 0.5404 - accuracy: 0.8110 - val_loss: 0.3876 - val_accuracy: 0.8671\n",
            "Epoch 78/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5368 - accuracy: 0.8130 - val_loss: 0.3876 - val_accuracy: 0.8672\n",
            "Epoch 79/100\n",
            "1170/1170 [==============================] - 65s 55ms/step - loss: 0.5310 - accuracy: 0.8151 - val_loss: 0.3876 - val_accuracy: 0.8672\n",
            "Epoch 80/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5334 - accuracy: 0.8129 - val_loss: 0.3879 - val_accuracy: 0.8669\n",
            "Epoch 81/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5380 - accuracy: 0.8139 - val_loss: 0.3876 - val_accuracy: 0.8667\n",
            "Epoch 82/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5373 - accuracy: 0.8140 - val_loss: 0.3877 - val_accuracy: 0.8672\n",
            "Epoch 83/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5394 - accuracy: 0.8104 - val_loss: 0.3875 - val_accuracy: 0.8673\n",
            "Epoch 84/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5273 - accuracy: 0.8135 - val_loss: 0.3876 - val_accuracy: 0.8671\n",
            "Epoch 85/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5345 - accuracy: 0.8092 - val_loss: 0.3873 - val_accuracy: 0.8672\n",
            "Epoch 86/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5409 - accuracy: 0.8118 - val_loss: 0.3871 - val_accuracy: 0.8677\n",
            "Epoch 87/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5325 - accuracy: 0.8131 - val_loss: 0.3870 - val_accuracy: 0.8679\n",
            "Epoch 88/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5401 - accuracy: 0.8107 - val_loss: 0.3870 - val_accuracy: 0.8677\n",
            "Epoch 89/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5375 - accuracy: 0.8111 - val_loss: 0.3869 - val_accuracy: 0.8677\n",
            "Epoch 90/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5394 - accuracy: 0.8109 - val_loss: 0.3869 - val_accuracy: 0.8679\n",
            "Epoch 91/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5399 - accuracy: 0.8117 - val_loss: 0.3870 - val_accuracy: 0.8673\n",
            "Epoch 92/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5328 - accuracy: 0.8146 - val_loss: 0.3868 - val_accuracy: 0.8673\n",
            "Epoch 93/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5377 - accuracy: 0.8104 - val_loss: 0.3872 - val_accuracy: 0.8671\n",
            "Epoch 94/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5348 - accuracy: 0.8109 - val_loss: 0.3871 - val_accuracy: 0.8671\n",
            "Epoch 95/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5434 - accuracy: 0.8109 - val_loss: 0.3871 - val_accuracy: 0.8676\n",
            "Epoch 96/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5403 - accuracy: 0.8130 - val_loss: 0.3866 - val_accuracy: 0.8675\n",
            "Epoch 97/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5318 - accuracy: 0.8169 - val_loss: 0.3865 - val_accuracy: 0.8677\n",
            "Epoch 98/100\n",
            "1170/1170 [==============================] - 66s 56ms/step - loss: 0.5373 - accuracy: 0.8120 - val_loss: 0.3865 - val_accuracy: 0.8675\n",
            "Epoch 99/100\n",
            "1170/1170 [==============================] - 66s 57ms/step - loss: 0.5300 - accuracy: 0.8156 - val_loss: 0.3866 - val_accuracy: 0.8670\n",
            "Epoch 100/100\n",
            "1170/1170 [==============================] - 67s 57ms/step - loss: 0.5221 - accuracy: 0.8139 - val_loss: 0.3864 - val_accuracy: 0.8680\n",
            "Epoch 1/100\n",
            " 982/1170 [========================>.....] - ETA: 5s - loss: 0.5339 - accuracy: 0.8114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-045d867f2be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFaLpxP-GAis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "5a3544db-cf2b-4d36-ab92-c00fbf48b074"
      },
      "source": [
        "#Visualización de los resultados en gráficas\r\n",
        "\r\n",
        "for i in range(len(history)):\r\n",
        "  plt.plot(history[i].history['accuracy'])\r\n",
        "plt.title('Exactitud del modelo')\r\n",
        "plt.ylabel('Exactitud')\r\n",
        "plt.xlabel('Época')\r\n",
        "plt.show()\r\n",
        "# \"Loss\"\r\n",
        "for i in range(len(history)):\r\n",
        "  plt.plot(history[i].history['val_loss'])\r\n",
        "plt.title('Métrica de pérdida')\r\n",
        "plt.ylabel('Pérdida')\r\n",
        "plt.xlabel('Época')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1auGTORGCJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21fa446-b601-42a4-d540-46872bdf68a2"
      },
      "source": [
        "#calculo del porcentajes de validación \r\n",
        "\r\n",
        "best_val_history = []\r\n",
        "for i in range(1,3):\r\n",
        "    model = load_model('modelos/transfer_learning_'+str(i)+'.hdf5')\r\n",
        "    best_val_history.append(model.evaluate(validation_dataset))\r\n",
        "    del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1170/1170 [==============================] - 30s 25ms/step - loss: 0.3721 - accuracy: 0.8718\n",
            "1170/1170 [==============================] - 31s 26ms/step - loss: 0.3598 - accuracy: 0.8752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_6lBjFkGDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d7d952-3c49-44f8-87ee-b43a5d43f343"
      },
      "source": [
        "#Calculo de promedios de validación y pérdida \r\n",
        "\r\n",
        "prom_loss = 0.0;\r\n",
        "prom_acc = 0.0;\r\n",
        "for i in range(len(best_val_history)):\r\n",
        "    prom_loss = prom_loss + best_val_history[i][0]\r\n",
        "    prom_acc = prom_acc + best_val_history[i][1]\r\n",
        "\r\n",
        "prom_loss = prom_loss / len(best_val_history)\r\n",
        "prom_acc = prom_acc / len(best_val_history)\r\n",
        "\r\n",
        "print(prom_loss)\r\n",
        "print(prom_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.43857941031455994\n",
            "0.8521474599838257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKxpuBxfGGlM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ec95db8-fc9b-4688-f494-2695e6f7cb29"
      },
      "source": [
        "import shutil\r\n",
        "shutil.make_archive(\"modelos_tipo\", 'zip', \"modelos\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/modelos_tipo.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}